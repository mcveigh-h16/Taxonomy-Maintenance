{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4a233-0bc4-434f-afdf-9037a0fdb8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae26380-c54c-4f0b-9dd8-5431f500ff89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f48d7430-9e3f-4bb2-8697-e38259271083",
   "metadata": {},
   "source": [
    "## pymupdf PDF miner script \n",
    "### Extact lines of text from pdf file by page number, convert it into a format for taxonomy update and merge mycobank data. Output saved to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eca689-7e5d-4c72-a907-272103ebedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96119053-6b62-4db5-9600-19b7a4aaa539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "doc = pymupdf.open(\"2024__The2024OutlineofFungiandfungus-liketaxa.pdf\") \n",
    "#out = open(\"output.txt\", \"wb\") # create a text output\n",
    "\n",
    "def extract_text_from_page_span(doc, start_page, end_page):\n",
    "    text = \"\"\n",
    "    for page in doc.pages(start_page, end_page, 1): \n",
    "        #text = page.get_text().encode(\"utf8\") # get plain text (is in UTF-8)\n",
    "        text += page.get_text(sort=True) #preserves the ws at the start of the line\n",
    "        #text += page.get_text()  #collapses ws at the start of the line\n",
    "    return text\n",
    "\n",
    "def join_indented_lines(text):\n",
    "    lines = text.splitlines()\n",
    "    result = []\n",
    "    previous_line = None\n",
    "\n",
    "    for line in lines:\n",
    "        #if line.startswith((' ', '\\t')):  # Check for indentation (spaces or tabs)\n",
    "        if line.startswith(' '):  # Check for indentation (spaces or tabs)\n",
    "            if previous_line is not None:\n",
    "                result[-1] = result[-1] + ' ' + line.lstrip()  # Append to previous\n",
    "            else:\n",
    "                result.append(line.lstrip()) #if the first line is indented, append it directly\n",
    "        else:\n",
    "            result.append(line)\n",
    "            previous_line = line\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "\n",
    "start_page = 40\n",
    "end_page = 332\n",
    "extracted_text = extract_text_from_page_span(doc, start_page, end_page)\n",
    "#extracted_text = re.sub(r\",\\s*\\n\", \" \", extracted_text)  #finds lines ending in a comma and appends them to the previous line\n",
    "text_lines = extracted_text.splitlines()\n",
    "result_text = join_indented_lines(extracted_text)\n",
    "#print(result_text)\n",
    "revised_text= (re.sub(r\"\\s\\d{4}\", \"\", result_text)) \n",
    "#print(revised_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa4ebc-39ce-44c9-98c8-f7b5e000225e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41073a6d-f631-4a0b-b1c7-4d766f36f92e",
   "metadata": {},
   "source": [
    "### Load text to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5756d3da-4775-4904-8b1a-d9be3a590cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phylum APHELIDIOMYCOTA Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg &amp; Abarenkov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Class Aphelidiomycetes Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg &amp; Abarenkov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aphelidiales Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg &amp; Abarenkov*Fp78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aphelidiaceae Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg &amp; Abarenkov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amoeboaphelidium Scherff. (5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Aphelidium Zopf (10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Paraphelidium Karpov, Moreira, López-García (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Protaphelidium Seliuk &amp; Karpov (1)*Seliuk &amp; Karpov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pseudaphelidium Schweik. &amp; Schnepf (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Phylum ASCOMYCOTA Caval.-Sm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Subphylum PEZIZOMYCOTINA O.E. Erikss. &amp; Winka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Class Arthoniomycetes O.E. Erikss. &amp; Winka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Arthoniales Henssen ex D. Hawksw. &amp; O.E. Erikss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Andreiomycetaceae B.P. Hodk. &amp; Lendemer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Andreiomyces B.P. Hodk. &amp; Lendemer (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Arthoniaceae Rchb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Amazonomyces Bat. &amp; Cavalc.(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Arthonia Ach. (ca 150)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      Text\n",
       "6   Phylum APHELIDIOMYCOTA Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov\n",
       "7   Class Aphelidiomycetes Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov\n",
       "8        Aphelidiales Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov*Fp78\n",
       "9            Aphelidiaceae Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov\n",
       "10                                                                                           Amoeboaphelidium Scherff. (5)\n",
       "11                                                                                                    Aphelidium Zopf (10)\n",
       "12                                                                         Paraphelidium Karpov, Moreira, López-García (2)\n",
       "13                                                                      Protaphelidium Seliuk & Karpov (1)*Seliuk & Karpov\n",
       "14                                                                                  Pseudaphelidium Schweik. & Schnepf (1)\n",
       "15                                                                                                                        \n",
       "16                                                                                            Phylum ASCOMYCOTA Caval.-Sm.\n",
       "17                                                                           Subphylum PEZIZOMYCOTINA O.E. Erikss. & Winka\n",
       "18                                                                              Class Arthoniomycetes O.E. Erikss. & Winka\n",
       "19                                                                        Arthoniales Henssen ex D. Hawksw. & O.E. Erikss.\n",
       "20                                                                                 Andreiomycetaceae B.P. Hodk. & Lendemer\n",
       "21                                                                                  Andreiomyces B.P. Hodk. & Lendemer (2)\n",
       "22                                                                                                                        \n",
       "23                                                                                                      Arthoniaceae Rchb.\n",
       "24                                                                                          Amazonomyces Bat. & Cavalc.(3)\n",
       "25                                                                                                  Arthonia Ach. (ca 150)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 2000) \n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "text_lines = revised_text.splitlines()\n",
    "\n",
    "def create_dataframe(text_lines):\n",
    "    df = pd.DataFrame(text_lines, columns=['Text'])\n",
    "    return df\n",
    "\n",
    "df = create_dataframe(text_lines)\n",
    "df = df.iloc[6:]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8d016-2eb2-485e-85b6-840def630856",
   "metadata": {},
   "source": [
    "#### Modify the extracted text now in pandas df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a6d2de-9af6-4af5-b5ea-f2b1bc90f109",
   "metadata": {},
   "source": [
    "#### Extract rank from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e90cb5-7c41-45f2-98f5-503952df2692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                    Text    Rank\n",
      "6        APHELIDIOMYCOTA Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov  Phylum\n",
      "7       Aphelidiomycetes Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov   Class\n",
      "8      Aphelidiales Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov*Fp78     NaN\n",
      "9          Aphelidiaceae Tedersoo, Sanchez-Ramirez, Kõljalg, Bahram, M. Döring, Schigel, T.W. May, M. Ryberg & Abarenkov     NaN\n",
      "10                                                                                         Amoeboaphelidium Scherff. (5)     NaN\n",
      "...                                                                                                                  ...     ...\n",
      "15148                                                                 Unemaeea Tedersoo, nom. inval. (1)*Tedersoo et al.     NaN\n",
      "15149                                                                                                                        NaN\n",
      "15150                                                                                Notes on new genera and higher taxa     NaN\n",
      "15151                                                                                                                        NaN\n",
      "15152                                                                                                                        NaN\n",
      "\n",
      "[15147 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_column_if_list_member_found(df, column_to_check, list_to_search, new_column_name):\n",
    "    for index, row in df.iterrows():\n",
    "        for item in list_to_search:\n",
    "            if item in row[column_to_check]:\n",
    "                df.loc[index, new_column_name] = item\n",
    "                df.loc[index, column_to_check] = row[column_to_check].replace(item, '').strip()\n",
    "                break # Stop searching after the first match                \n",
    "    return df\n",
    "search_rank = ['Phylum', 'Class', 'Subphylum']\n",
    "\n",
    "df = add_column_if_list_member_found(df, 'Text', search_rank, 'Rank')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf786f-6105-4b93-a715-0f82ca29074a",
   "metadata": {},
   "source": [
    "### Find and populate Organism name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ae998c4-bb92-4b58-93a5-2a9094b9a0eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_22024\\4073477577.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'incertae sedis'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#print(f\"Row {index}: Contains 'incertae sedis': {row['Text']}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#works but the split needs to be adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#df[['OrgName', 'Authority']] = df['Text'].str.split('incertae sedis', n=1, expand=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OrgName'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Authority'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"(.+?incertae sedis)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\apps\\admin_installs\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4296\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4297\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4298\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4299\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4300\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4301\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4302\u001b[0m         elif (\n",
      "\u001b[1;32mc:\\apps\\admin_installs\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4354\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4355\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iset_not_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\apps\\admin_installs\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4373\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4377\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Columns must be same length as key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4379\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4380\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0migetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "#Try this\n",
    "pattern = 'incertae sedis'\n",
    "pattern2 = r\"(.+?incertae sedis)\"\n",
    "df['OrgName'] = np.nan\n",
    "df['Authority'] = np.nan\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if isinstance(row['Text'], str) and 'incertae sedis' in row['Text']:\n",
    "        #print(f\"Row {index}: Contains 'incertae sedis': {row['Text']}\")\n",
    "        #works but the split needs to be adjusted\n",
    "        #df[['OrgName', 'Authority']] = df['Text'].str.split('incertae sedis', n=1, expand=True)\n",
    "        df[['OrgName', 'Authority']] = df['Text'].str.extract(pattern2, expand=False)\n",
    "                                        \n",
    "\n",
    "    else:\n",
    "        #print(f\"Row {index}: Does not contain 'incertae sedis': {row['Text']}\")\n",
    "        df[['OrgName', 'Authority']] = df['Text'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "    #df.loc[df['Text'].str.contains(r\"(.*\" + pattern + \")\"), ['OrgName', 'Authority']] = df.loc[df['Text'].str.contains(r\"(.*\" + pattern + \")\"), 'Text'].str.split((r\"(.*\" + pattern + \")\"), expand=True)\n",
    "\n",
    "\n",
    "\n",
    "#df['OrgName']= df['Text'].str.split(r\"(.*\" + pattern + \")\", expand=False)\n",
    "#df['OrgName']= df['Text'].str.extract(r\"(.*\" + pattern + \")\", expand=False)\n",
    "\n",
    "\n",
    "#Splitting name from authority\n",
    "#df[['OrgName', 'Authority']] = df['Text'].str.split(' ', n=1, expand=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52831d66-cdb0-43bc-a42a-baba58be5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this\n",
    "def add_organism_name(df, column_to_check, pattern, new_column_name):\n",
    "    for index, row in df.iterrows():\n",
    "        #for item in search:\n",
    "        if pattern in row[column_to_check]:\n",
    "            pass\n",
    "            #df.loc[index, new_column_name] = df['Text'].str.extract(r\"(.*\" + pattern + \")\", expand=False)\n",
    "                #df.loc[index, column_to_check] = row[column_to_check].replace(item, '').strip()\n",
    "        else:\n",
    "            df.loc[index, new_column_name] = df['Text'].str.split(' ', n=1, expand=True)\n",
    "    return df\n",
    "    \n",
    "pattern = 'incertae sedis'\n",
    "df = add_organism_name(df, 'Text', pattern, 'OrgName')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pattern = r'incertae sedis'\n",
    "#df['Name1'] = df['Text'].str.extract(pattern, expand=True)\n",
    "#df['Name1']= df['Text'].str.extract(r\"(.*\" + pattern + \")\", expand=False)\n",
    "\n",
    "#Splitting name from authority\n",
    "#df[['Name2', 'Authority in paper']] = df['Text'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "#df = df.drop('Text', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48719138-66c8-49bc-8e83-83bc9edd0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this\n",
    "def process_data(df, column_name, pattern, new_column_name):\n",
    "    \"\"\"\n",
    "    Searches for a pattern in a DataFrame column and adds a new column \n",
    "    based on whether the pattern is found.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column to search within.\n",
    "        pattern (str): The regular expression pattern to search for.\n",
    "        new_column_name (str): The name of the new column to create.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with the new column.\n",
    "    \"\"\"\n",
    "    def check_pattern(text):\n",
    "        if isinstance(text, str) and re.search(pattern, text):\n",
    "            #return \"Pattern Found\"\n",
    "            #return df['Text'].str.extract(r\"(.*\" + pattern + \")\", expand=False)\n",
    "            df['OrgName']= df['Text'].str.extract(r\"(.*\" + pattern + \")\", expand=False)\n",
    "        else:\n",
    "            #return \"Pattern Not Found\"\n",
    "            #return df['Text'].str.split(' ', n=1, expand=True)\n",
    "            df[['OrgName', 'Authority in paper']] = df['Text'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "    df[new_column_name] = df[column_name].apply(check_pattern)\n",
    "    return df\n",
    "\n",
    "\n",
    "pattern = r'incertae sedis'\n",
    "new_column_name = \"OrgName\"\n",
    "df = process_data(df, 'Text', pattern, new_column_name)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92f8fb-85c9-4c81-82ef-d50c3e955c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern(df, text_column, pattern):\n",
    "    \"\"\"\n",
    "    Creates a new column in a Pandas DataFrame where if a pattern is found in the text column, it extracts the match and all preceding text, \n",
    "    otherwise splits the first word of the text into two new columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        text_column (str): The name of the column containing the text to search.\n",
    "        pattern (str): The pattern to search for in the text.\n",
    "    \n",
    "    Returns: \n",
    "        pd.DataFrame: The updated DataFrame with new columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['OrgName'] = np.nan\n",
    "    #df['first_word'] = np.nan\n",
    "    df['Authority'] = np.nan\n",
    "    \n",
    "    for index, text in enumerate(df[text_column]):\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            start_index = match.start()\n",
    "            df.loc[index, 'OrgName'] = text[:start_index + match.end()]\n",
    "            df.loc[index, 'Authority'] = text[start_index + match.end:()]\n",
    "        else:\n",
    "            words = text.split()\n",
    "            if len(words) > 0:\n",
    "                df.loc[index, 'OrgName'] = words[0]\n",
    "                df.loc[index, 'Authority'] = \" \".join(words[1:])\n",
    "    \n",
    "    return df\n",
    "\n",
    "pattern = r'incertae sedis'\n",
    "extract_pattern(df, 'Text', pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4039f5-4675-4f57-b351-4caf7f41fce4",
   "metadata": {},
   "source": [
    "### Complete populating rank based on text patterns in Organism Name -mycotina=subphylum, -mycetes=class, -ales=order, -aceae=family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e558e-175e-4c86-a4df-f52d3fd37be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e27957-04e8-4eb0-af15-d0fb58f2f44e",
   "metadata": {},
   "source": [
    "### Merge in Mycobank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abc499-3b1e-4dbd-8d95-a8f2092ade24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879fb455-42a5-4816-9f5b-85751f3d02f3",
   "metadata": {},
   "source": [
    "### Save final output to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972303bd-e933-4843-b7a8-7475ae563cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel (r'C:\\Users\\mcveigh\\Documents\\PythonPC\\PDFminertest.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d853590-7062-4616-9361-9a50707c8e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: Does not contain 'berry': apple pie\n",
      "Row 1: Does not contain 'berry': banana\n",
      "Row 2: Does not contain 'berry': cherry tart\n",
      "Row 3: Does not contain 'berry': date pudding\n",
      "Row 4: Contains 'berry': elderberry\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'col': ['apple pie', 'banana', 'cherry tart', 'date pudding', 'elderberry']}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    if isinstance(row['col'], str) and 'berry' in row['col']:\n",
    "        # Do something if 'col' is a string and contains 'berry'\n",
    "        print(f\"Row {index}: Contains 'berry': {row['col']}\")\n",
    "    else:\n",
    "        # Do something else if 'col' is not a string or doesn't contain 'berry'\n",
    "        print(f\"Row {index}: Does not contain 'berry': {row['col']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b894da4-5678-4e7f-a3a4-0c6d858d84b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
